---
title: "RAVE-Cluster Pipeline Documentation"
output:
  html_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
# rebuild package
devtools::load_all(path = rstudioapi::getActiveProject())

# This code block sets up the engine environment
# Please do not remove me
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
build_pipeline <- raveio::configure_knitr()
# Debug use
# Please set working directory to be in the source file
if(FALSE){
  local({
    f <- c(
      file.path(tempdir(), "rave-builtin-cluster", '0.0.1', 'settings.yaml'),
      'settings.yaml'
    )
    f <- f[file.exists(f)][[1]]
    settings <- raveio::load_yaml(f)
    list2env(as.list(settings), envir = globalenv())
  })
}
debug <- TRUE
```

Let's start by printing the summary of this project

```{rave load_project, language = "R", export = "project"}
library(raveio)
project <- raveio::as_rave_project(project = project_name)
project
```

Reformat `input_groups`, give them reasonable group names

```{rave reformat_input_groups, export = "condition_groups"}
condition_groups <- lapply(input_groups, function(group){
  group_name = group$group_name
  if(is.null(group_name)){
    group_name = sprintf('Group %d', ii)
  } else {
    group_name <- trimws(group_name)
    if(!nchar(group_name)) {
      group_name <- sprintf('Group %d', ii)
    }
  }
  group$group_name <- group_name
  group
})
```

The next step is enter the project export folder and load data files exported by `Power Explorer` module. The folder can be found inside of `project$group_path("power_explorer")`, named `exports`. Package function `import_configurations (raveclusters)` is designed to load these data.

The data exported by `Power Explorer` are data frames containing power for each trial, time point, and electrode. The data is too large and might exhaust the computer's memory. Function `import_configurations` internally collapses the data frame by condition, grouping by `Condition`, `Time`, `Electrode`, `Subject`, and calculate mean power (`Pct_Change_xxx`, `z_score_xxx`, `decibel_xxx`), and generate trial count (column count)

```{rave load_data, language = "R", export = "source_data"}
# get the exported path of power explorer
search_paths <- file.path(
  project$group_path("power_explorer"),
  "exports"
)
source_data <- raveclusters::import_configurations(
  search_paths = search_paths, 
  file_names = source_files)

if(!length(source_data)) {
  stop("`raveclusters`: All requested files are missing from the search path:\n",
       paste0("    ", source_files, collapse = "\n"))
}

if(!is.list(source_data))

if(debug) {
  print(names(source_data))
}
source_data$data
```

Parse the ROI selector and generate columns to filter `source_data$data`

```{rave get_ROI_var, language = "R", export = "roi_var"}
# subset with only the selected ROI variable
roi_list <- c("VAR_IS_ROI_Hemisphere", "VAR_IS_ROI_freesurferlabel", 
              "VAR_IS_ROI_Group", "VAR_IS_ROI_Block")
if(length(roi_options$variable)) {
  roi_var <- paste0('VAR_IS_ROI_', roi_options$variable)
} else {
  roi_var <- NULL
}


```

Apply ROI filters

```{rave apply_RIO_filters, language = "R", export = "raw_table"}
library(raveclusters)
raw_table <- source_data$data

roi_list <- c("VAR_IS_ROI_Hemisphere", "VAR_IS_ROI_freesurferlabel", 
              "VAR_IS_ROI_Group", "VAR_IS_ROI_Block")
excluded_roi <- roi_list[!roi_list %in% roi_var]

selected_names <- names(raw_table)
selected_names <- selected_names[!selected_names %in% excluded_roi]

raw_table = raw_table[, !names(raw_table) %in% excluded_roi, with = FALSE]

#select based on the ROI selector
use_regex <- ( roi_options$roi_ignore_gyrus_sulcus || roi_options$roi_ignore_hemisphere )

filter_by_roi <- roi_options$value
if(length(roi_var) && length(filter_by_roi)) {
  na_rm <- TRUE
  if("N/A" %in% filter_by_roi) {
    filter_by_roi <- filter_by_roi[!filter_by_roi %in% "N/A"]
    na_rm <- FALSE
  }
  
  raw_table <- raveclusters::table_apply_roi(
    table = raw_table, roi_column = roi_var,
    roi = filter_by_roi, use_regex = use_regex,
    na_rm = na_rm)
}

```


Parse the event selector to find corresponding column names in `source_data$data`

```{rave find_data_column_name, language = "R", export = "var_name"}
var_name <- sprintf("%s_%s", power_unit, analysis_event)
var_name <- var_name[var_name %in% names(source_data$data)]
```

Collapse the filtered `source_data$data` again. This time calculate weighted mean (by trial count) for each group. This table contains the following columns:
* `Subject`: subject code
* `Electrode`: electrode number
* `VAR_IS_ROI_xxx`: ROI filters
* `Time`: time point (in second)
* `Group`: group index
* `Variable`: event variable
* `Value`: collapsed (mean) power data

```{rave collapse_data_by_condition_group, languae = "R", export = "collapsed"}
library(rutabaga)
library(data.table)
collapsed = lapply(seq_along(condition_groups), function( ii ){

  # get the condition groups
  group = condition_groups[[ ii ]]
  # group_name = group$group_name
  # 
  # 
  # if(is.null(group_name) && group_name == ''){
  #   group_name = sprintf('Group %d', ii)
  # }

  group_condition = group$group_conditions
# 
#   # data within plotting time window
#   sub_plot = raw_table[raw_table$Condition %in% group_condition &
#                          raw_table$Time %within% plot_time_window, ]
# 
#   # data within analysis time window
#   sub = sub_plot[sub_plot$Time %within% analysis_time_window, ]
# 
#   sub_plot$Time = paste0(sub_plot$Time, '_', ii)
#   sub_time = paste0(sub$Time, '_',ii)

  # collapse the power, weighted by count
  group_columns <- c("Subject", "Electrode", roi_var, "Time")
  collapsed_table <- raw_table[
    Condition %in% group_condition,
    lapply(.SD, function(x, w) {
      if(!is.numeric(x)) {
        x <- as.double(x)
      }
      sel <- !is.na(x)
      if(!any(sel)) { return(NA_real_) }
      sum((x * w)[sel]) / sum(w[sel])
    }, w = count),
    keyby = group_columns,  # group by and sort by group_columns
    .SDcols = var_name
  ]
  
  # melt by var_name
  melted_table <- data.table::melt(collapsed_table, id.vars = group_columns, measure.vars = var_name, variable.factor = FALSE, variable.name = "Variable", value.name = "Value")
  # melted_table$Time <- paste0(melted_table$Time, "_", ii)
  melted_table$Group <- ii
  
  # fml <- Subject + Electrode + VAR_IS_ROI_freesurferlabel ~ Time
  # fml[[2]][[3]] <- parse(text = roi_var)[[1]]
  # 
  # collapsed_mean <- lapply(var_name, function(var){
  #   reshape2::dcast(
  #     sub_plot,
  #     fml,
  #     fun.aggregate = mean, value.var = var
  #   )
  # }
  # )
  # 
  # merged <- Reduce(function(a, b){
  #   # b <- collapsed[[1]]
  #   merge(a, b, all = FALSE,
  #         by = c("Subject", 'Electrode',roi_var))
  # }, collapsed_mean)
  # 
  # return(list(
  #   collapsed_mean = merged,
  #   group_name = group_name,# is this necessary?
  #   group_index = ii,# and this?
  #   sub_time = sub_time
  # ))
  melted_table
})

# rbind
collapsed <- data.table::rbindlist(collapsed)

if(debug) {
  print(collapsed)
}
```

Reshape and "cast" the `collapsed` table to a matrix to apply the clustering algorithms, resulting in `collapsed_array`. `collapsed_array` is a matrix:
* Each row is a combination of `Subject`, `Electrode`, and event `Variable`. You can use `attr(collapsed_array, "item_table")` to obtain the lookup table
* Each column is a time-point and group combination, sorted by group first, and then time in ascending order. You can use `attr(collapsed_array, "time_table")` to obtain the column lookup table

```{rave reshape_collapsed_data_to_matrix, export = "collapsed_array"}

# Split per subject, electrode, Variable (event)
roi_val <- collapsed[[roi_var]]
roi_val_mode <- mode(roi_val)
roi_val[is.na(roi_val)] <- "NA"
collapsed$Unit <- sprintf(
  "%s^%s^%s^%s",
  collapsed$Subject,
  collapsed$Electrode,
  collapsed$Variable,
  roi_val
)
collapsed_array <- reshape2::acast(
  data = collapsed, value.var = "Value",
  formula = Unit ~ Time + Group, 
  fill = NA_real_, fun.aggregate = function(x){
    sel <- is.na(x)
    if(all(sel)) { return(NA_real_) }
    mean(x[!sel])
  }
)

dnames <- dimnames(collapsed_array)
names(dnames) <- c("Unit", "Time")

# reorder time
time_mat <- stringr::str_split_fixed(dnames$Time, "_", n = 2)
time_order <- order(as.integer(time_mat[,2]), as.double(time_mat[,1]))

dnames$Time <- dnames$Time[time_order]
collapsed_array <- collapsed_array[, time_order, drop = FALSE]
dimnames(collapsed_array) <- dnames

time_mat <- as.data.frame(stringr::str_split_fixed(dnames$Time, "_", n = 2))

# store time information to the array
names(time_mat) <- c("Time", "Group")
time_mat$Time <- as.double(time_mat$Time)
time_mat$Group <- as.integer(time_mat$Group)
attr(collapsed_array, "time_table") <- time_mat

# Store row information
item_table <- stringr::str_split_fixed(dnames$Unit, "\\^", n = 4)
item_table <- as.data.frame(item_table)
names(item_table) <- c("Subject", "Electrode", "Event", "ROI")
item_table$Electrode <- as.integer(item_table$Electrode)
item_table$ROI[item_table$ROI == "NA"] <- NA
mode(item_table$ROI) <- roi_val_mode
attr(collapsed_array, "item_table") <- item_table

if(debug) {
  print(names(attributes(collapsed_array)))
}
```

We z-score baseline based on `collapsed_array`:

* For each group `ii`, find the corresponding sub-matrix
* Calculate mean and standard deviation for each row. Make sure the `NA` missing values are properly handled

The returned `baseline` variable is a list of sub-matrices, each of which represents z-scored data within the corresponding group.

```{rave z-score_baseline_collapsed_array, export = "baseline"}
library(rutabaga)
time_table <- attr(collapsed_array, "time_table")

baseline <- lapply(seq_along(condition_groups), function( ii ){
  column_sel <- time_table$Group == ii
  
  if(use_baseline) {
    baseline_sel <- column_sel & (time_table$Time %within% baseline_time)
  
    bl <- collapsed_array[, baseline_sel, drop = FALSE]
    blmean <- rowMeans(bl, na.rm = TRUE)
    if(sum(baseline_sel) < 2) {
      stop("Cannot z-score data. Please increase your baseline range.")
    }
    blstdev <- apply(bl, 1, stats::sd, na.rm = TRUE)
    re <- ((collapsed_array[, column_sel, drop = FALSE]) - as.vector(blmean)) / as.vector(blstdev)
    
  } else {
    re <- collapsed_array[, column_sel, drop = FALSE]
  }
  
  list(
    data = re,
    time = time_table$Time[column_sel]
  )
})
```

Variable `baseline` is a list of matrices. We could also `cbind` these matrices, resulting in `baseline_array`. However, I don't find this combined array that useful (see next block)

```{rave column-bind_baseline_list, export="baseline_array"}
baseline_array <- do.call("cbind", lapply(baseline, function(x){
  x$data
}))
attributes(baseline_array) <- attributes(collapsed_array)
```

The matrix `baseline_array` is not that useful for the following considerations:
1. We are more interested in data within the analysis time-window
2. (Most) clustering algorithms cannot take in `NA` missing values
3. Some rows might have `NA` within analysis time-window, and we need to remove these rows.

Therefore our strategy is to:
* For each group, slice the columns (`baseline` list items) such that the corresponding time points fall within the `analysis_time_window`
* Column-bind the sliced data
* Find complete cases (`complete.cases (stats)`) of the matrix
* Subset, yield `indata_analysis`

Since the first step is done at each condition group level, `baseline` is more convenient than `baseline_array`

The result, `indata_analysis` has an attribute `attr(indata_analysis, "complete_cases")`, is a logical vector that can be used in the future to find which rows enter the clustering analysis in `collapsed_array` and `baseline_array`.

```{rave slice_data_by_anslysis_window, export="indata_analysis"}
library(rutabaga)
# Filter by analysis window first
indata_analysis <- lapply(baseline, function(item){
  # item <- baseline[[1]]
  item$data[, item$time %within% analysis_time_window, drop = TRUE]
})
indata_analysis <- do.call("cbind", indata_analysis)

# Only keep complete data (No NA)
sel <- stats::complete.cases(indata_analysis)
if(!sum(sel)) {
  stop("The analysis window cannot have missing data, but all signals contain missing values. Try narrowing the analysis range")
}
indata_analysis <- indata_analysis[sel,,drop = FALSE]
attr(indata_analysis, "complete_cases") <- sel

item_table <- attr(collapsed_array, "item_table")
item_table <- item_table[sel, , drop = FALSE]
attr(indata_analysis, "item_table") <- item_table
```

`indata_plot` is similar to `indata_analysis`, but no slice in time.

```{rave slice_data_by_ploting_window, export="indata_plot"}
library(rutabaga)

sel <- attr(indata_analysis, "complete_cases")
item_table <- attr(indata_analysis, "item_table")

# Filter by analysis window first
indata_plot <- lapply(baseline, function(item){
  # cols <- item$time %within% plot_time_window
  # list(
  #   time = item$time[cols],
  #   data = item$data[sel, cols, drop = TRUE]
  # )
  list(
    time = item$time,
    data = item$data[sel, , drop = TRUE]
  )
})
attr(indata_plot, "item_table") <- item_table
```

Calculate the distance matrix based on `indata_analysis`

```{rave measure_distance, language = "R", export = 'dis'}

if(isTRUE(distance_method == '1 - correlation')){
  dis = as.dist(1-cor(t(indata_analysis)))
}else if(isTRUE(distance_method == 'DTW')){
  dis = as.dist(dtw::dtwDist(indata_analysis))
}else{
  dis = dist(indata_analysis, method = distance_method)
}
```

Calculate cluster index

```{rave calculate_clustering_index, export = "cluster_index"}
# indata_analysis <- results$indata_analysis
# dis <- results$dis
# hclust_method <- 'ward.D2'
# 
max_nclusters <- optim_clusters$max_nclusters
cvi_methods <- optim_clusters$methods

if(cluster_method == "K-Medois") {
  cluster_results <- sapply(seq_len(max_nclusters), function(k){
    tmp <- cluster::pam(x = dis, diss = TRUE, k = k)
    tmp$clustering
  })
} else {
  cf <- stats::hclust(dis, method = hclust_method)
  cluster_results <- stats::cutree(cf, k = seq_len(max_nclusters))
}

cluster_index <- raveclusters::cluster_index(
  indata_analysis, cluster_results, dist = dis, methods = cvi_methods)
best_nclusters <- raveclusters::best_nclusters(cluster_index)
attr(cluster_index, "best_nclusters") <- best_nclusters
attr(cluster_index, "clusters") <- cluster_results
if(debug) {
  print(best_nclusters)
}
```

Perform clustering algorithms. Variable `clusters` has four columns:
* `Subject`, `Electrode`, `Event`, `Cluster`

```{rave apply_clustering, language = "R", export = 'clusters'}
n_clust = min(input_nclusters, nrow(dis))

item_table <- attr(indata_analysis, "item_table")
sel <- attr(indata_analysis, "complete_cases")
item_table <- item_table[sel, , drop = FALSE]

if (cluster_method == "H-Clust"){
  hcl = stats::hclust(dis, method = hclust_method)
  item_table$Cluster <- stats::cutree(hcl, k = n_clust)
  attr(item_table, "hclust") <- hcl
} else if (cluster_method == "PAM") {
  km <- cluster::pam(dis, k = n_clust,  cluster.only = TRUE, 
                     keep.data = FALSE, 
                     keep.diss = FALSE)
  item_table$Cluster <- km
}


# rename
clusters <- item_table

if(debug) {
  print(dim(clusters))
  print(head(clusters))
}
```


Calculate mean and standard error of mean on the data slice, used to generate plots

```{rave get_mse, language = "R", export = "mse"}
library(dipsaus)
cluster_idx <- sort(unique(clusters$Cluster))

# get time range
time <- sort(unique(unlist(lapply(indata_plot, "[[", "time"))))

# time x (mean, se) x condition group x cluster
mse <- array(NA_real_, c(length(time), 2, length(indata_plot), length(cluster_idx)))

for(ii in seq_along(cluster_idx)) {
  ci <- cluster_idx[[ii]]
  
  for(jj in seq_along(indata_plot)) {
    item <- indata_plot[[jj]]
    
    sel <- time %in% item$time
    
    group_mse <- apply(item$data[clusters$Cluster == ci,,drop = FALSE], 2, 
                 dipsaus::mean_se, na.rm = TRUE, se_na_as_zero = FALSE)
    
    mse[sel, , jj, ii] <- t(group_mse)
  }
}

dimnames(mse) <- list(
  Time = time,
  Stat = c("mean", "mse"),
  Group = seq_along(indata_plot),
  Cluster = cluster_idx
)

# 
# mse <- lapply(indata_plot, function(item){
#   # item <- indata_plot[[1]]
#   
#   list(
#     time = item$time,
#     mse = apply(item$data[clusters$Cluster == ci,,drop = FALSE], 2, 
#                 function(x) {
#                   dipsaus::mean_se(x, na.rm = TRUE, se_na_as_zero = TRUE)
#                 })
#   )
# })

```


Assign each row a color

```{rave assign_color, export = "cluster_table"}
cluster_table <- clusters
ns <- asNamespace("raveclusters")
colors = ns$get_palette(color_scheme)
cluster_idx <- sort(unique(clusters$Cluster))
colors <- colors[seq_along(cluster_idx)]
names(colors) <- cluster_idx

cluster_table$Color <- colors[clusters$Cluster]
attr(cluster_table, "color_space") <- colors

attr(cluster_table, "cluster_idx") <- cluster_idx
attr(cluster_table, "nclusters") <- length(cluster_idx)
head(cluster_table)
```

Perform MDS to project `indata_analysis` to two dimensional space

```{rave MDS_projection, export = "mds_result"}

if(ncol(indata_analysis) < 2) {
  mds_result <- NULL
  return(mds_result)
}

if(ncol(indata_analysis) == 2) {
  mds_result <- indata_analysis
  rownames(mds_result) <- NULL
} else {
  
  mds_result <- switch (
    mds_distance,
    `1 - correlation` = {
      cmdscale(
        as.dist(1 - cor(t(indata_analysis))),
        k = 2
      )
    }, {
      cmdscale(
        dist(indata_analysis, method = mds_distance),
        k = 2
      )
    }
  )
  
}

mds_result <- as.data.frame(mds_result)
names(mds_result) <- c("x", "y")

```

Prepare the clustering plots for `visNetwork` to show the clustering tree

```{rave generate_cluster_tree, export = "imgbase64"}
# img <- file.path(image_dir, sprintf('%s.png', codes))
#   
#   image <- sapply(img, function(x){
#     base64enc::dataURI(file = x)
#   })
plot_args <- list(
  use_baseline = use_baseline,
  power_unit = power_unit,
  analysis_time_window = analysis_time_window,
  condition_groups = condition_groups,
  indata_plot = indata_plot
)

cluster_mat <- attr(cluster_index, "clusters")
item_table <- attr(indata_plot, "item_table")

imgbase64 <- dipsaus::fastqueue2()

# create png
tmpfile <- tempfile(pattern = "ravecluster_visnet_", 
                    tmpdir = tempdir(check = TRUE),
                    fileext = ".png")

invisible(
  lapply(seq_len(ncol(cluster_mat)), function(ii) {
    cluster <- cluster_mat[, ii]
    item_table$Cluster <- cluster
    mse <- raveclusters::cluster_mse(indata_plot = indata_plot, 
                                      cluster = cluster)
    plot_args$cluster_table <- item_table
    plot_args$mse <- mse
    raveclusters::cluster_visualization(
      plot_args, decorators = NULL, cex = 2,
      one_plot = FALSE,
      before_plot = function(){
        png(filename = tmpfile, width = 640, height = 480)
      },
      after_plot = function(){
        grDevices::dev.off()
        imgbase64$add(
          base64enc::dataURI(file = tmpfile)
        )
        unlink(tmpfile)
      }
    )
  })

)


```

```{rave plot_cluster_tree, export = "cluster_tree_plot"}
cluster_tree_plot <- raveclusters::cluster_tree(list(
  cluster_index = cluster_index,
  imgbase64 = imgbase64
))
if(debug) {
  print(cluster_tree_plot)
}
```

## Pipeline Visualization

```{r build, echo=FALSE}
build_pipeline(make_file = "make-rave-builtin-cluster.R")
Sys.setenv("RAVE_PIPELINE" = normalizePath("."))
# raveio::pipeline_visualize(level_separation = 20)
local({
  pipe_dir <- raveio:::activate_pipeline(".")
  targets::tar_destroy(ask = FALSE)
  targets::tar_visnetwork(targets_only = TRUE, shortcut = FALSE, level_separation = 1000, zoom_speed = 0.3)
})
```








